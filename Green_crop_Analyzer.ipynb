{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjznOcRKZVcSlu+4ibgWS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditigarg08/Green-Crop-Analyzer/blob/main/Green_crop_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A82f9uHE14Wl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# NOTE: The following cells are for Google Colab only\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dataset\n",
        "PlantVillage dataset can be downloaded from Kaggle:\n",
        "https://www.kaggle.com/datasets/emmarex/plantdisease\n"
      ],
      "metadata": {
        "id": "1CZZd6d96MEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d emmarex/plantdisease -p /content\n",
        "!unzip -o /content/plantdisease.zip -d /content/dataset\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "83VBH6hD7Ci3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow keras keras-core keras-nightly tf-keras tensorflow-hub tensorflow-text tensorflow-decision-forests jax jaxlib ydf ml-dtypes protobuf flax orbax-checkpoint dopamine-rl keras-hub -q\n",
        "!pip install tensorflow==2.18.0 numpy==1.26.4 matplotlib seaborn opencv-python-headless --quiet\n"
      ],
      "metadata": {
        "id": "VE5ndLPMponq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Keras:\", tf.keras.__version__)\n",
        "print(\"GPU:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "id": "B8dnbe74qSuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y keras keras-core keras-nightly tf-keras\n",
        "!pip install -U tensorflow==2.18.0 numpy==1.26.4 --quiet\n"
      ],
      "metadata": {
        "id": "5UwHCKQPq3OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Keras:\", tf.keras.__version__)\n"
      ],
      "metadata": {
        "id": "GGXZsOIBrDm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"MobileNetV2 imported successfully!\")\n"
      ],
      "metadata": {
        "id": "sl8N77Kgrug0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import os, matplotlib.pyplot as plt\n",
        "\n",
        "DATA_DIR = '/content/dataset/PlantVillage'\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (128,128)\n",
        "EPOCHS = 10\n",
        "FINE_TUNE_EPOCHS = 5\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "# Split automatically (80/20)\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR, validation_split=0.2, subset='training', seed=123,\n",
        "    image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical'\n",
        ")\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    DATA_DIR, validation_split=0.2, subset='validation', seed=123,\n",
        "    image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical'\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(\"Classes:\", class_names)\n",
        "\n",
        "train_ds = train_ds.map(lambda x,y: (preprocess_input(x), y)).cache().prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.map(lambda x,y: (preprocess_input(x), y)).cache().prefetch(AUTOTUNE)\n",
        "\n",
        "# Data Augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "])\n",
        "\n",
        "# Base Model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(*IMG_SIZE,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=(*IMG_SIZE,3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n",
        "\n",
        "# Fine-tune last layers\n",
        "base_model.trainable = True\n",
        "fine_tune_at = len(base_model.layers) - 30\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_fine = model.fit(train_ds, validation_data=val_ds, epochs=FINE_TUNE_EPOCHS)\n",
        "\n",
        "# Save model to Drive\n",
        "MODEL_PATH = \"models/trained_model_mobilenetv2.keras\"\n",
        "CLASS_NAMES_PATH = \"models/class_names.json\"\n",
        "model.save(MODEL_PATH)\n",
        "print('‚úÖ Model saved to Drive successfully!')\n"
      ],
      "metadata": {
        "id": "Xfgs_oAxriBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'] + history_fine.history['accuracy'])\n",
        "plt.title('Training Accuracy')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['val_accuracy'] + history_fine.history['val_accuracy'])\n",
        "plt.title('Validation Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ztk1i-GSuSoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "uuoFp2z_uVhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "\n",
        "for fname in uploaded.keys():\n",
        "    img_path = f'/content/{fname}'\n",
        "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
        "    arr = image.img_to_array(img)\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    arr = preprocess_input(arr)\n",
        "\n",
        "    pred = model.predict(arr)\n",
        "    idx = np.argmax(pred)\n",
        "\n",
        "    # Display results\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"{fname} ‚Üí Prediction: {class_names[idx]}\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "61tv4W7OvXvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('/content/drive/MyDrive/class_names.json', 'w') as f:\n",
        "    json.dump(class_names, f)\n",
        "print('‚úÖ Saved class names to Drive')\n"
      ],
      "metadata": {
        "id": "UeBC-nGZv_p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# NOTE: The following cells are for Google Colab only\n"
      ],
      "metadata": {
        "id": "seeYu9gJ0zed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit tensorflow pillow pyngrok --quiet\n"
      ],
      "metadata": {
        "id": "yuWAeSZVCpL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "# NOTE:\n",
        "# Download the trained model from Google Drive and place it in /models/\n",
        "MODEL_PATH = \"models/trained_model_mobilenetv2.keras\"\n",
        "CLASS_NAMES_PATH = \"class_names.json\"\n",
        "\n",
        "# Load model and class names\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = tf.keras.models.load_model(MODEL_PATH)\n",
        "    return model\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "with open(CLASS_NAMES_PATH, \"r\") as f:\n",
        "    class_names = json.load(f)\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "st.title(\"üåø Green Crop Analyzer\")\n",
        "st.write(\"Upload a leaf image to detect plant disease.\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\"Upload leaf images\", type=[\"jpg\", \"jpeg\", \"png\"], accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    for uploaded_file in uploaded_files:\n",
        "        img = Image.open(uploaded_file)\n",
        "        st.image(img, caption=f\"Uploaded: {uploaded_file.name}\", use_column_width=True)\n",
        "\n",
        "        img = img.resize(IMG_SIZE)\n",
        "        arr = image.img_to_array(img)\n",
        "        arr = np.expand_dims(arr, axis=0)\n",
        "        arr = preprocess_input(arr)\n",
        "\n",
        "        pred = model.predict(arr)\n",
        "        idx = np.argmax(pred)\n",
        "\n",
        "        st.success(f\"Prediction: **{class_names[idx]}**\")\n"
      ],
      "metadata": {
        "id": "Ha7t8yUJCwrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken (\"YOUR_SECRET_TOKEN\")\n"
      ],
      "metadata": {
        "id": "sYC_kCy_Dt5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "url = ngrok.connect(8501)\n",
        "print(\"Your Web App URL:\", url)\n"
      ],
      "metadata": {
        "id": "7Ls0V0BjC3HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .gitignore\n",
        "# üîê Secrets\n",
        "kaggle.json\n",
        "*.env\n",
        "ngrok.yml\n",
        "\n",
        "# üß† Models\n",
        "*.h5\n",
        "*.keras\n",
        "*.ckpt\n",
        "\n",
        "# üìä Dataset\n",
        "dataset/\n",
        "\n",
        "# üêç Python\n",
        "__pycache__/\n",
        ".ipynb_checkpoints/"
      ],
      "metadata": {
        "id": "jQKhjI5rlpYB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}